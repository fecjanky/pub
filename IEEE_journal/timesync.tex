% !TeX encoding = UTF-8
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
\documentclass[journal]{IEEEtran}

\renewcommand\IEEEkeywordsname{Keywords}

\pagenumbering{gobble}

\usepackage[utf8]{inputenc}

% *** GRAPHICS RELATED PACKAGES ***
%\usepackage[pdftex]{graphicx}
\usepackage{graphicx}
%\usepackage[dvips]{graphicx}
% to place figures on a fixed position
\usepackage{float}


% *** PDF, URL AND HYPERLINK PACKAGES ***
\usepackage{url}

% correct bad hyphenation here
\hyphenation{NetFPGA}

\usepackage{xcolor}

\usepackage{siunitx}

\usepackage{bytefield}

% \renewcommand\note[1]{} % uncomment this line to hide notes

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%


% LaTeX quick ref
%
% \cite{refname} to place citation
%
% \label{label_name} to place a label, which can be reference by \ref{label_name}
%
% new paragraph -> empty line between text
%
% \noindent to not indent paragraphs first line
%
% create list with : \begin{itemize} \end{itemize}
% \begin{itemize
% \renewcommand to renew numbering \labelitemi{--} to select bullet type
% \item item elem 1
% \item item elem2
% \end{itemize}
%
% et alia (et al.) should be emphasized (i.e in italic) with \emph{et al.}
%
% to add figure, htb is placement selector , !overrid internal paramters
%\begin{figure}[!htb]
%    \centering
%    \includegraphics[width=0.5\textwidth]{FIG.png}
%    \caption{Caption}
%    \label{fig:label}
%\end{figure}
%
% ~ concatenates dynamic text with literals
%
% long dash is --
%
% `is single quoted' , ``is double qouted"
%
% to autoformat with latexindent: latexindent -w  -m -l defaultSettings.yaml ProtoImplFPGA.tex


\begin{document}
% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Time Synchronization Solution for FPGA-based Distributed Network Monitoring}
%\titleheader{25th Telecommunications forum TELFOR 2017 \hfill Serbia, Belgrade, November 21-22, 2017.}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{Ferenc Nandor Janky and Pal Varga \thanks{The authors are with the Department of Telecommunications and
 \mbox{MediaInformatics}, Faculty of Electrical Engineering and Informatics,
Budapest University of Technology and Economics,
Magyar tudósok körútja 2., 1117 Budapest, Hungary (phone: +36704213213; e-mail: \mbox{fecjanky@gmail.com} and pvarga@tmit.bme.hu)}}
%\IEEEauthorblockN{Ferenc N\'{a}ndor Janky and P\'{a}l Varga}
%\IEEEauthorblockA{Dept. of Telecommunications and Media Informatics\\Budapest University of Technology and Economics\\
%2 Magyar Tud\'{o}sok krt., Budapest, Hungary, H-1117\\
%Email: \{fjanky, pvarga\}@tmit.bme.hu }

%
%}%


% make the title area
\maketitle

\begin{abstract}
    \boldmath
    Distributed network monitoring solutions face various challenges with the increase of line speed, the extending variety of protocols, and new services with complex KPIs. This paper addresses one part of the first challenge: faster line speed necessitates time-stamping with higher granularity and higher precision than ever. Proper, system-wide time-stamping is inevitable for network monitoring and traffic analysis point of view. It is hard to find feasible time synchronization solutions for those systems that has nation-wide, physically distributed probes.
    
    Current networking equipment reside in server rooms, and have many legacy nodes. Access to GPS signals are complicated in these places, and Precision Time Protocol (PTP) is not seem to be supported by all network nodes in the near future -- so high precision time-stamping is indeed a current problem. This paper suggests a novel, practical solution to overcome the obstacles. 
    
    The core idea is that in real-life, distributed network monitoring systems operate with a few, finite number of probe-clusters, and their site should have a precise clock provided by PTP or GPS somewhere in the building. The distribution of time information within a site is still troublesome, even within a server rack. This paper presents a closed control loop solution implemented in an FPGA-based device in order to minimize the jitter, and compensate the calculated delay.
    
\end{abstract}

\begin{IEEEkeywords}
    network monitoring, time synchronization, hardware acceleration, closed control loop 
\end{IEEEkeywords}

% no keywords
\section{Introduction}\label{sec:Intro}

Network monitoring has a well-established practice at telecommunication operators. There are fundamentally different solutions available -- depending on what kind of data are initially available and how it is gathered. The least flexible solutions are based on the functional networking elements: they can provide pre-digested reports, statistical counters, and occasionally (when not under heavy load), even detailed information on the actual messages. Some operators use standalone protocol analyzers, which do not suffer from the temporal, load-related bottlenecks -- rather, they have spatial data capture issues: only a segment of the network is visible at any given time. On the other hand, complete traffic information can be gathered by network-wide traffic monitoring. These latter solutions are based on passive, distributed probes; central processing entities; and client software -- also distributed -- at the operating personnel. This paper discusses a peculiar problem of such systems: effective time synchronization among the entities.

Network traffic analysis requires the understanding of the order of the messages appearing in the network, even if they appear at different interfaces. This makes high resolution and high precision timestamping the basic requirement, beside lossless message capture. 
While there are standardized network protocols available for tackling this issue, there are practical obstacles in their network-wide usage. Although the Network Time Protocol (NTP) is widely available \cite{NTP_standard}, it cannot be used as a general purpose synchronization protocol. In fact, the message transfer delay between NTP clients and servers are not compensated, hence the different nodes end up setting their local time to a clock value with a random delay. The typical order of the forwarding delay in current core routers is in the 0.5-5 microseconds range, depending on the traffic volume -- among other factors. Since the minimum packet interarrival-time is 0.672 microsecond even at a 1Gbit\/s link (and 67.2 nanoseconds for a 10Gbit\/s link), such delays cannot be left without compensation for time synchronization.

Precision Time Protocol (PTP), on the other hand covers the delay-compensation issue well \cite{PTP_standard}. Unfortunately, PTP is not at all wide-spread, even after 10 years of commercialization for PTPv2. The concept, however, necessitates that all network nodes in the path have PTPv2 capability. Otherwise -- even if one node cannot compute and share its delay data --, compensation of time information is not possible.

Another solution could be to introduce time information of GPS (Global Positioning System) satellites into the nodes -- this is not feasible, since rack cabinets in server rooms lack the line of sight.

We can suppose that at least one machine at each monitoring site has the possibility to get synchronized to the master clock of the network (e.g. through PTP or GPS). Nevertheless, synchronizing all clocks within the site with nanosecond-range precision, is still a challenge.

This paper presents a solution for the time synchronization issues of systems with FPGA-based monitoring probes. What makes FPGA a key player here is that hardware-acceleration removes the jitter of operating system and protocol-stack delay from the equation. The delay of handling time information within an FPGA is constant, we can calculate with it precisely -- and compensate this delay for te time-stamp.

In this paper we focus of the time synchronization challenges of a monitoring site. The implemented solution is based on the practical pre-requisite that each site has a reference clock available for the monitoring system. This paper suggests an FPGA-based clock synchronization method for the distributed monitoring equipment, more precisely, its interface cards.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures_raw/Network_monitoring.png}
    \caption{A generic architecture for distributed network monitoring}
    \label{fig:network_monitoring}
\end{figure*}

\section{Network Monitoring supported by FPGA-based Probes}\label{sec:NetMon}
\subsection{The Generic Concept of Distributed Network Monitoring}

The distributed network monitoring architecture depicted by Figure~\ref{fig:network_monitoring} supports local, probe-based pre-processing (timestamping, requirement-based packet chunking, filtering criteria-based distribution) and central, deep analysis (correlation of messages and transactions, data record compilation, statistics generation), even on-the-fly \cite{old_5}. The time-based ordering and interleaving of messages are enabled by the hardware-accelerated timestaming, providing nanosecond-range resolution with sub-microsecond precision. The information stored locally at the distributed Monitoring Probes can be accessed by client applications of the operator. Besides, the Monitoring Probes send pre-digested data to the Servers for correlation (creating e.g. Call Data Records, CDRs), as well as periodic reports containing their calculated statistics.

Since user data and control data are often carried over the same channels, their division requires message analysis on network- or transaction-level (e.g., IP- or TCP-level). The changing traffic patterns force the operators to look for new tools to process even the user traffic. The first step towards this is the compilation of XDRs (eXtended Data Records) based on control- and user-plane messages and transactions. These often contain message-level timestamps, as well. Based on these data, the deep traffic analysis tools provide valuable information towards business-intelligence and network optimization. Besides, all nodes can be configured to report directly to the NOC (Network Operations Center).

Operators use the network-wide, passive monitoring for fault detection, service quality assurance, and resource planning, among others. Besides lossless data capture, network monitoring covers further functions, as well:
\begin{itemize}
\renewcommand\labelitemi{--}
\item precise timestamping, ordering;
\item compilation, search and fetch of Call Data Records (CDRs) and Extended Data Records (XDRs);
\item calculation and reporting of Key Performance Indicators, KPIs;
\item Call Tracing at various complexity levels;
\item bit-wise message decoding for protocol analysis; etc. 
\end{itemize}

All these functions are present in the network monitoring practice, since beside user-level data analysis, network analysis is important from connection-level to application-level, as well.

System elements of the described generic architecture can be implemented in many ways. In the SGA-7N system -- which serves as the base implementation for the presented solution --  monitoring probes of the presented system are called ``Monitors''. These consist of three main building blocks: a high performance Field Programmable Gate Array (FPGA)-based custom hardware platform, a firmware dedicated for network monitoring, and the probe software. The reconfigurable property of the FPGA chip enables to turn the Monitor hardware platform into a high performance networking device, e.g., network monitor, switch, router, firewall or intrusion detection system. Nevertheless, as a network monitoring system, it supports distributed and lossless packet level monitoring of Ethernet links for 1 or 10 Gbit\/s.

\subsection{FPGA-based packet processing}

There are many features that make FPGAs useful in packet processing tasks. The main concept itself allows \emph{parallel processing} of the input data. Different, simultaneous tasks can be carried out at each clock cycle on the same data, which in this case is the packet header. Besides, the \emph{input word length} is much greater for FPGAs (getting 90 bytes) than for modern CPUs (64 bits). Furthermore, FPGA are set up in hardware-defined languages, and they are indeed \emph{reconfigurable} hardware: their internal wiring can be changed within milliseconds. These features enable FPGA-based hardware platforms to become high performance networking devices, e.g., network monitors, switches, routers, firewalls or intrusion detection systems.

Beside providing sufficient resources for switching and routing at 1 or 10 Gbit\/s, the design of SGA-GPLANAR \cite{GPLANAR} and SGA-10GED \cite{10GED} includes some special, network monitoring-related requirements, namely 
\begin{itemize}
\renewcommand\labelitemi{--}
\item lossless packet capture,
\item 64-bit timestamping with sub-microsecond resolution,
\item header-only capture: configurable depth of decoding,
\item on-the-fly packet parsing by hardware,
\item parameterized packet/flow generator for mass testing.
\end{itemize}

Various applications then require other supported functionalities. As an example, the high-speed monitoring application \cite{HPSR_2015} consists of the following sub-modules:
\begin{itemize}
\renewcommand\labelitemi{--}
\item timestamping every frame upon reception;
\item packet decoding from layer 2  up to the application layer;
\item packet filtering with a reconfigurable rule-set to decide what we do with a given packet;
\item packet chunking: packets can be truncated depending on the matching rule;
\item packet distribution: to distribute packets by different criteria: IP flows, fragment steering, steering based on mobile core network parameters, etc.;
\item packet headering: monitoring information is stored in a specified header format.
\end{itemize}

These features and capabilities make the FPGA a suitable enabler of hardware acceleration within the Monitoring Probes.

\section{Challenges and Requirements in Detail}\label{sec:Challanges}

%TODO(Fec) : 0.5 oldal
%- Monotonic clock
%- Remote locations, skewing clock
%- Adaptation to legacy systems 
%- Precision requirements (Fendler Tomi TDK)

For a distributed monitoring solution described in the previous sections, there is a strong requirement for having
a \emph{monotonic clock}. Otherwise, packet reordering would happen even with a single monitoring node (changing its clock) -- and this is not feasible, since traffic analysis is heavily dependent upon packet timestamps. As a consequence, the need for monotonic system time is inherent.

Another challenge comes from the fact that a distributed monitoring system has its components geographically
separated from each other, therefore the clock frequency and the time information of the clocks of the nodes have to be
frequency- and phase-synchronized to each other with some given threshold. This problem has many solutions, e.g., using
GPS based synchronization
systems~\cite{GPS-CLOCK}. As a drawback, this requires additional installation expenditures on an indoor site that has no installed
antenna system to carry the GPS signal inside the building and could also result in extensive cabling work.
A convenient alternative for this is to use network time synchronization that utilizes the telecommunication network for
exchanging packets as per a specified, designated protocol to achieve frequency and phase synchronization. Examples for this
are Network Time Protocol (NTP)~\cite{NTP} and Precision Time Protocol (PTP)~\cite{PTP}.

When speaking about time synchronization, the following properties describe a clock:
\begin{itemize}
    \item accuracy -- \emph{i.e.} how good is the time information compared to some reference
    \item precision -- \emph{i.e.} how precise is a tick of the clock compared to some reference
    \item stability -- \emph{i.e.} how does the clock frequency change	e.g., over time or based on external
          temperature changes etc.
\end{itemize}

The biggest challenge of all -- as usual -- is to adapt to the existing monitoring framework described in
\ref{sec:NetMon}
with minimal modifications to the existing solution, while satisfying all the precision and accuracy related requirements.
As mentioned before, the platform for proof-of-concept is the SGA-7N monitoring system, which utilizes FPGA-based monitoring cards. These are capable of capturing on high-speed network interfaces -- with fine-grained timestamping capabilities --, and they have their own, existing time-keeping facilities.

In order to tackle all the above mentioned issues with a solution fitting into the network monitoring architecture, we suggested to create a new FPGA-based card that implements these functions:
\begin{itemize}
    \item network time synchronization,
    \item local time synchronization,
    \item interfacing with the existing nodes -- OAMP functionalities.
\end{itemize}

The following sections describe this solution, and show its feasibility in the running monitoring system.

\IEEEpubidadjcol %%%%%% ezmiez? %%%%%%%%%%

\section{Architecture of the Distributed Time Synchronized Monitoring System}

\subsection{Generic concept}
For providing easy adaptation into the existing system, and also taking into account FPGA resource usage, a hybrid
solution
has been designed. This solution implements network time synchronization in a standalone card that distributes the digital timing
information over a dedicated control bus, as illustrated by Figure~\ref{fig:concept}.

The synchronization framework provides a platform-independent agent that
can be integrated into the existing FPGA cards' top level VHDL (VHSIC Hardware Description Language) modules, and is used through a well-defined and portable interface.

The agent itself has low complexity, and as a result, the solution does not waste CLB (Configurable Logic Block) resources -- as if the whole network
synchronization stack were instantiated N times on all monitoring node cards. Furthermore, this results in better internal
synchronization
compared to the replicated stacks, since those can have skew to each other (within the boundaries), as specified by their
protocol.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.45\textwidth]{figures_raw/concept.png}
    \caption{Fitting the time synchronization function into the generic, distributed network monitoring concept}
    \label{fig:concept}
\end{figure}

As seen on Figure~\ref{fig:concept}, each node has its own network synchronization function, therefore the accuracy and
precision between two monitoring nodes can be guaranteed only to an extent that the utilized time synchronization
protocol provides. Due to the uncompensated delay of routers, switches and transmission paths, this is in the magnitude of milliseconds of a software implementation of NTP. This precision, however, can be increased by using FPGAs for hardware acceleration. Depending on the PTP version used, and the underlying network capabilities, this can be fall into the magnitude of nanoseconds.

The main idea of the solution is to install a local time-distribution bus between the nodes within a site. This allows us to achieve nanosecond-range synchronicity, as there is
less perturbation between the HW implementations of the transmitting and receiving ends -- no OS scheduler, no network etc. Moreover, frequency synchronization can also be easily achieved by implementing a synchronous bus -- i.e., transmitting
the
clock signal along with the data.

\subsection{External time synch. subsystem design and implementation}\label{sec:External-Impl}

When selecting the candidate for implementing the external time synchronization function,
three protocols were considered:
\begin{itemize}
    \item Network Time Protocol (NTP),
    \item Precision Time Protocol v1 (PTPv1),
    \item Precision Time Protocol v2 (PTPv2).
\end{itemize}

In order to achieve the best synchronization between PTPv2 clocks, the protocol requires PTPv2-enabled switches/routers throughout the network. These do the bookkeeping of the processing delay values in the synchronization packets as they traverse through the network. Without this feature, the achievable synchronicity in a multi-hop network is around the same as by using PTPv1.

Since PTPv2 is not widely available in current networks, we concluded in either selecting NTP or PTPv1, due to their simplicity. PTPv1 has way more modes of operation when compared to NTP. Still, these two protocols are operating based on semantically the same principle when determining the round
trip time and offset
compared to a reference clock entity. Although there are significant differences originated from their packet structure, the
timestamp format and also the epoch that could result in more complex implementation if PTPv1 would be chosen.
Still, the NTP timestamp format includes a 32-bit unsigned seconds field spanning 136 years and a 32-bit fraction field resolving 232
picoseconds the prime epoch, or base date of era 0, is 0 h 1 January 1900 UTC -- i.e., when all bits are zero.

Based on the requirements, the above considerations, and the Occam principle, the design decision led to selecting \emph{NTP protocol to be used} for synchronizing the
FPGA-based monitoring cards through a card that is responsible for implementing the external and internal (see
Section~\ref{sec:Internal-Impl}) time synchronized function called SGA-Clock.

Each FPGA-based packet processing and networking protocol implementation has its own complexity. There are several
readily available implementations that can be used for packet processing in FPGAs with some limited flexibility when it
comes to interconnecting it
with other modules. The one that has been used for the current implementation is a flexible solution for Protocol
Implementations within FPGAs. The solution detailed in \cite{ProtoImpl} provides a generic framework in VHSIC Hardware
Description Language (VHDL) that enables rapid prototyping of networking protocols. Among many other things it provides
the following main features
\begin{itemize}
    \renewcommand \labelitemi{--}
    \item supports protocol module interconnection via layering;
    \item handles reception and transmission of Protocol Data Units (PDUs) with queuing;
    \item provides a high level interface for separating and combining	Protocol Control Information (PCI) and Service Data Unite (SDU),
          forwarding, pausing or dropping SDUs;
    \item provides a unified way to handle Interface Control Information (ICI), SDU, and PDU events (e.g., error signalling);
    \item adds support of auxiliary information that travels along with messages
    \item provides components for common tasks recurring during implementing networking protocols
          (de/serialization, arbitration etc.).
\end{itemize}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.4\textwidth]{figures_raw/system_sketch.pdf}
    \caption{Fundamental building block of the FPGA networking framework used for the Protocol Implementation}
    \label{fig:system_sketch}
\end{figure}

The framework's basic building block (shown by Figure~\ref{fig:system_sketch}) was used for implementing a pure FPGA-based
UDP/IP protocol stack with ARP on top of 802.3 Ethernet. It provides a platform with deterministic timing for the
likewise FPGA-based
implementation of NTP. For each of these protocols the corresponding protocol-specific parts have been described in
VHDL, using the generic framework.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.5\textwidth]{figures_raw/ntp-sketch.pdf}
    \caption{NTP module block diagram of components}
    \label{fig:ntp-impl}
\end{figure}

The internal structure of the NTP module is shown by Figure~\ref{fig:ntp-impl}. The NTP Poller component is responsible
for the NTP packet transmission and reception, and implementing the On-Wire protocol
for determining the offset -- based on the packet messages. The packet-handling part is also implemented
through the Protocol Implementations framework. The NTP ClockFilter component is there to regulate the offset values
presented by the poller by ordering the results based on delay, updating internal state variables, calculating jitter,
and
suppressing spikes based on jitter and last successful test time. If the offset data got passed the filter stage, it gets
forwarded for further processing by the NTP Discipline module.

The NTP Discipline module controls the clock module -- by adjusting the time increment -- based on the filtered offset
data. The NTP clock module provides an interface for controlling the time increment that itself is added to the clock
register in each system clock cycle -- thus
implementing the clock functionality. The time information is fed back to each module as illustrated on
Figure~\ref{fig:ntp-impl}.
This chain of modules with the feedback is another realization of a closed loop control chain described in the following section.

\subsection{Internal time synch. subsystem design and implementation}\label{sec:Internal-Impl}

The internal time information synchronization function is responsible for having all clocks in all monitoring functions
to be completely synchronized within a monitoring node. Since this is an internal component the amount of perturbation
that potentially affects this subsystem is considered minimal compared to the external time synchronization subsystem.

The elements of this subsystem are:
\begin{itemize}
    \item digital bus that is able to transmit time and status information
    \item a driver module of that bus that resides in the Network clock synchronization function
    \item receiver modules attached to that bus performing local time synchronization
\end{itemize}

Internally all FPGA boards implementing a monitoring function can operate from different power supply units as a
consequence ground level
isolation is necessary over the bus. For reducing the physical layer complexity
a point-to-point bus system has been designed. To be able to maximize the number of connected clients connected the
bus utilizes an asynchronous serial communication using 2 wires. The communication protocol executed by the driver
module
multiplexes arbitrary data units and the time information over the bus into frames -- equipped with error detection
code --
in an alternating pattern.That results in periodic transmission of valid time information.

The parameters of the physical signalling are:
\begin{itemize}
    \item LVCMOS33 levels for representing logical values
    \item asymmetric signal transmission
    \item \SI{15.625}{\mega\hertz} clock frequency with 4x oversampling
    \item NRZ coding
\end{itemize}

The frame format used on the bus is shown on Figure~\ref{fig:HiSTI-frame}. The frame starts with an all 1's preamble
followed by a start bit with value 0. The type field is used to discriminate between the payload type, when T=1 it
indicates that the payload is
time information otherwise it's data -- on this data channel an overlay data communication protocol can be used.
The time format is in line with the external time synchronization \emph{i.e.} it uses the NTP
time format for representing the time information. For detecting transmission errors on the bus a CRC-8 value is
calculated
for the \emph{`Type'} and \emph{`Payload'} fields and appended to the frame that is checked on frame reception for
detecting
transmission errors.

Given the parameters above the frame time is 90/\SI{15.625}{\mega\hertz} = \SI{5.76}{\micro\second} and since every
other frame carries time information the clock on the receiver side can be disciplined/controlled on a
\SI{11.52}{\micro\second}
basis. Under such short period of time even low quality, non-temperature controlled crystal oscillators have negligible
drift
as a result this update period is adequate for the network monitoring use case.

\begin{figure}
    \begin{bytefield}{32}
        \bitheader{0-31} \\
        \bitbox{16}{All ones} & \bitbox{1}{S} & \bitbox{1}{T} & \bitbox{14}{time/data} \\
        & \wordbox{1}{time/data} \\
        & \bitbox{18}{} & \bitbox{8}{CRC-8}
    \end{bytefield}
    \caption{High-Speed Timestamp Interface frame format}
    \label{fig:HiSTI-frame}
\end{figure}

The receiver module de-multiplexes the data and the time information from the payload of the received frame. It also
verifies that the received frame's CRC-8 value matches the calculated one. If no errors were detected then it feeds the

time information into a module that performs time synchronization using a closed loop control.
This closed loop control has a simple proportional controller as illustrated on Figure~\ref{fig:closed-loop}. The clock
module
is incrementing a clock counter with an increment in each system clock period. Since the oscillator frequency was not
configurable in
existing system the way to discipline the clock was through adjusting the time increment itself.
Even though the increment is adjusted proportionally to the error signal it is a integral controller due to nature of
the time increment process that adds the current time increment to the time counter on each clock cycle
-- \emph{i.e.} integral of a function of the error signal over time.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{figures_raw/time_control_loop.png}
    \caption{Internal clock control loop}
    \label{fig:closed-loop}
\end{figure*}

In theory a I controller in a closed loop system can eliminate error signal -- \emph{i.e.} the time difference --
completely.
With this design the solution contains a digital time distribution bus and a module that realizes the
closed control loop as seen on Figure~\ref{fig:closed-loop}.

\subsection{Realized system}

The realized system with all internal components is shown on Figure~\ref{fig:realized-system} where the external time
synchronization -- as presented in Section~\ref{sec:External-Impl} -- is done by the SGA Clock card -- visible in the
bottom right part -- and the internal time synchronization -- described in Section~\ref{sec:Internal-Impl} --
is performed over the local bus with agent modules synthesized in all monitoring cards acting as slaves on the
high-speed timestamp interfaces also driven by the SGA Clock card acting as a master.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{figures_raw/clock_architecture.png}
    \caption{The realized system with all internal components}
    \label{fig:realized-system}
\end{figure}

\section{Verification \& Results}

%TODO(Fec) : 1.5 oldal
%- Describe the verification method in detail
%- Matlab graph, long-term vs. short-term 

For verifying the solution extensive testing and measurements have been carried out. For inspecting the degree of
synchronization to the master NTP clock a packet capturer operating in promiscuous mode was installed on the Ethernet
segment on which the FPGA implementation of the NTP slave was connected. The NTP packets used for synchronization were
captured bidirectionally. This packet capture then was filtered for those NTP packets that had all 4 timestamps used in

the On-Wire protocol to calculate the offset from the reference clock value. With software based post-processing the
offset information was extracted along with the time elapsed from the start of measurement -- which is determined by
the
first NTP packet present in the packet capture.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures_raw/pcap-NTP.png}
    \caption{Measurement results - packet capture}
    \label{fig:pcap-NTP}
\end{figure*}

A sample packet capture is visible on Figure~\ref{fig:pcap-NTP}. The statistical parameters -- like the drift and real
offset -- of the device was determined by
fitting a linear curve on the offset values. For the actual measurement presented in this paper the capture was taken
for approximately 3 hours.
The measurement values and the fitted curve plot can be seen on Figure~\ref{fig:results}.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures_raw/plot2.png}
    \caption{Measurement results - plot of derived data}
    \label{fig:results}
\end{figure*}

The curve fitted on this measurement shows that there was a fix \SI{14.52}{\micro\second} offset compared to the
reference clock. As presented in Section~\ref{sec:Challanges}
having a precise and stable clock -- with known offset -- is as good as having an accurate one. As for the stability
the first order stability of the
device is \SI{-0.7}{1/\nano\second}. This precision and stability are considered adequate for satisfying the
requirements of the external time synchronization part.

As for the internal synchronization part it is by design accurate as it is a synchronous bus system with no
disturbances -- under normal operating conditions -- as a
consequence the clock accuracy over that bus is determined by the bit width and the refresh rate of the digital
time-stamp transmitted over the bus. As it was described in Section~\ref{sec:Internal-Impl} the
time-stamp is 64 bits wide also using the NTP binary fractional representation. Given that the time-stamp is accurate
to the last bit then the theoretical accuracy is \SI{232.83}{\pico\second}.

\section{Conclusion}

In this paper, we introduced a general time synchronization solution for a high performance, lossless network monitoring system called SGA-7N that is based on a reconfigurable architecture. The probes of the system are called ``Monitors'', which consists of three main building blocks: a high performance Field Programmable Gate Array (FPGA)-based custom hardware platform, a firmware dedicated for network monitoring, and the probe software. The reconfigurable property of the FPGA chip enables to turn the Monitor hardware platform into a high performance networking device -- among others, a network monitoring probe. Beside supporting distributed and lossless packet level monitoring of Ethernet links for 1 or 10 Gbit\/s of the described system, the FPGA serves as the base platform of the time synchronization solution for the interface cards of the Monitors.
...

References: 0.5 oldal


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures_raw/fj_profile.png}}]{Ferenc Nandor Janky} 
received the MSc degree in Electrical Engineering from BME, Budapest, Hungary, in 2013.
He gained experienced while working for various telecommunication companies including Vodafone,AITIA International Inc. and Ericsson.
His main areas of interest are network protocols, FPGA programming and software development. 
Ferenc is currently working as a C++ software developer for an international corporate bank.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures_raw/VP_profile.jpg}}]{Pal Varga}
 is Associate Professor at BME, Hungary, where he got his M.Sc. (1997) and Ph.D. (2011) degrees from. Besides, he is director in AITIA International Inc.  Earlier he was working for Ericsson Hungary and Tecnomen Ireland, as software design engineer and system architect, respectively.  His main research interest include communication systems, network performance measurements, root cause analysis, fault localisation, traffic classification, end-to-end QoS and SLA issues, as well as hardware acceleration, and Internet of Things.
% He has been involved in various industrial as well as European research and development projects in these topics.

\end{IEEEbiography}



% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/

\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{references}

%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

%\begin{thebibliography}{1}
%
%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
% 0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%
% \end{thebibliography}

\end{document}
